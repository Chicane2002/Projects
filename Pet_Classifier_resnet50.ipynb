{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chicane2002/Projects/blob/main/Pet_Classifier_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgfI643gH99W"
      },
      "outputs": [],
      "source": [
        "#The following changes have been made in the given code:\n",
        "#1. Batch normalisation\n",
        "#2. Hyperprameter tuning\n",
        "#3. Learning rate scheduler\n",
        "#4. Manual grid parameter tuning of epochs\n",
        "\n",
        "#Accuracy increased from 83% to 88.4%\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images_fp = '/content/drive/MyDrive/images'\n",
        "dataset_name = 'tanlikesmath/the-oxfordiiit-pet-dataset'\n",
        "\n",
        "image_names = [os.path.basename(file) for file in glob.glob(os.path.join(images_fp, '*.jpg'))]\n",
        "#image_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA3_TIsJVASt"
      },
      "outputs": [],
      "source": [
        "labels = set([' '.join(name.split('_')[:-1:]) for name in image_names])\n",
        "i=0\n",
        "l={}\n",
        "while i<len(labels):\n",
        "  l[list(labels)[i]]=i\n",
        "  i+=1\n",
        "def label_encode(label):\n",
        "  return l[label]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP6FbHPJYvhY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "features = []\n",
        "labels = []\n",
        "image_size=(224,224)\n",
        "\n",
        "for name in image_names:\n",
        "  label=' '.join(name.split('_')[:-1:])\n",
        "  label_encoded=label_encode(label)\n",
        "  if label_encoded != None:\n",
        "    img = load_img(os.path.join(images_fp,name))\n",
        "    img = tf.image.resize_with_pad(img_to_array(img,dtype='uint8'),*image_size).numpy().astype('uint8')\n",
        "    image=np.array(img)\n",
        "    features.append(image)\n",
        "    labels.append(label_encoded)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J0VGmizPzU9"
      },
      "outputs": [],
      "source": [
        "features_array=np.array(features)\n",
        "labels_array=np.array(labels)\n",
        "labels_one_hot=pd.get_dummies(labels_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvPflewcPu-i"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Train:60%,val:25%,test:20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_array, labels_one_hot, test_size=0.2, random_state=48)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=48)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP4NYINJS-br"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as pp_i\n",
        "from keras.layers import RandomFlip, RandomRotation, BatchNormalization\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX5LBAGZUYCR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    RandomFlip(\"horizontal_and_vertical\"),\n",
        "    RandomRotation(0.24),\n",
        "  ]\n",
        ")\n",
        "\n",
        "preprocess_input = pp_i\n",
        "\n",
        "prediction_layers= Dense(37,activation='softmax')\n",
        "\n",
        "resnet_model = ResNet50(include_top=False,pooling='avg',weights='imagenet')\n",
        "resnet_model.trainable=False\n",
        "\n",
        "# Building model\n",
        "\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = resnet_model(x, training=False)\n",
        "x = Dropout(0.2)(x)\n",
        "x = BatchNormalization()(x)  # Mini-batch normalization\n",
        "outputs = prediction_layers(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.005),\n",
        "              loss=CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = 0.005\n",
        "    if epoch > 10:\n",
        "        return initial_lr * 0.1\n",
        "    return initial_lr\n",
        "# Hyper parameter tuning for learning rate\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Model training with hyperparameter tuning\n",
        "for e in range(10,31):\n",
        "  model_history = model.fit(X_train, y_train,\n",
        "                            epochs=e,\n",
        "                            batch_size=32,\n",
        "                            validation_data=(X_val, y_val),\n",
        "                            callbacks=[lr_scheduler])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1t73ieREAP8cU2mZqMlJgWqb0uj1cxylT",
      "authorship_tag": "ABX9TyNPLJzNpI2PTa6Zt9jbnkIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}